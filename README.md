# ðŸš¢ Titanic ETL Pipeline

## ðŸ”¹ Overview
This project implements an **ETL (Extract, Transform, Load) pipeline** for the **Titanic dataset**. The goal is to clean, transform, and load data for analysis, making it ready for modeling and visualization.

---

## ðŸ“š Steps Covered
- **Extract:** Load raw Titanic CSV data from local files.  
- **Transform:**  
  - Handle missing values  
  - Convert categorical features into numeric codes  
  - Create derived features (like family size, title, etc.)  
- **Load:** Insert cleaned and transformed data into a database (Supabase/PostgreSQL).  
- **Validate:** Check for nulls, duplicates, and ensure data consistency.  
- **Analyze:** Generate summary statistics and visualizations like survival rates, passenger class distributions, and age histograms.  

---
